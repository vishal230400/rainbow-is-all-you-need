{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !apt install python-opengl\n",
    "    !apt install ffmpeg\n",
    "    !apt install xvfb\n",
    "    !pip install PyVirtualDisplay==3.0\n",
    "    !pip install gymnasium==0.28.1\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    # Start virtual display\n",
    "    dis = Display(visible=0, size=(400, 400))\n",
    "    dis.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08. Rainbow\n",
    "\n",
    "[M. Hessel et al., \"Rainbow: Combining Improvements in Deep Reinforcement Learning.\" arXiv preprint arXiv:1710.02298, 2017.](https://arxiv.org/pdf/1710.02298.pdf)\n",
    "\n",
    "We will integrate all the following seven components into a single integrated agent, which is called Rainbow!\n",
    "\n",
    "1. DQN\n",
    "2. Double DQN\n",
    "3. Prioritized Experience Replay\n",
    "4. Dueling Network\n",
    "5. Noisy Network\n",
    "6. Categorical DQN\n",
    "7. N-step Learning\n",
    "\n",
    "This method shows an impressive performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. \n",
    "\n",
    "![rainbow](https://user-images.githubusercontent.com/14961526/60591412-61748100-9dd9-11e9-84fb-076c7a61fbab.png)\n",
    "\n",
    "However, the integration is not so simple because some of components are not independent each other, so we will look into a number of points that people especailly feel confused.\n",
    "\n",
    "1. Noisy Network <-> Dueling Network\n",
    "2. Dueling Network <-> Categorical DQN\n",
    "3. Categorical DQN <-> Double DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "from typing import Deque, Dict, List, Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# download segment tree module\n",
    "if IN_COLAB:\n",
    "    !wget https://raw.githubusercontent.com/curt-park/rainbow-is-all-you-need/master/segment_tree.py\n",
    "\n",
    "from segment_tree import MinSegmentTree, SumSegmentTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Same as the basic N-step buffer. \n",
    "\n",
    "(Please see *01.dqn.ipynb*, *07.n_step_learning.ipynb* for detailed description about the basic (n-step) replay buffer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int, \n",
    "        size: int, \n",
    "        batch_size: int = 32, \n",
    "        n_step: int = 1, \n",
    "        gamma: float = 0.99\n",
    "    ):\n",
    "        # Initialize buffer to store observations (state representations)\n",
    "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        # Initialize buffer to store the next observations\n",
    "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
    "        # Initialize buffer to store actions taken\n",
    "        self.acts_buf = np.zeros([size], dtype=np.float32)\n",
    "        # Initialize buffer to store rewards received\n",
    "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
    "        # Initialize buffer to store done flags (True if episode ends)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        \n",
    "        # Set the maximum buffer size and batch size for sampling\n",
    "        self.max_size, self.batch_size = size, batch_size\n",
    "        # Initialize pointer for the current position in the buffer\n",
    "        # and variable to track the number of transitions currently stored\n",
    "        self.ptr, self.size = 0, 0\n",
    "        \n",
    "        # For N-step Learning:\n",
    "        # Create a deque to store recent transitions (of length n_step)\n",
    "        self.n_step_buffer = deque(maxlen=n_step)\n",
    "        # Number of steps to consider for N-step transitions\n",
    "        self.n_step = n_step\n",
    "        # Discount factor (gamma) used for reward calculation in N-step transitions\n",
    "        self.gamma = gamma\n",
    "\n",
    "\n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray, \n",
    "        act: np.ndarray, \n",
    "        rew: float, \n",
    "        next_obs: np.ndarray, \n",
    "        done: bool,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        # Create a transition tuple (current state, action, reward, next state, done flag)\n",
    "        transition = (obs, act, rew, next_obs, done)\n",
    "        # Append the transition to the N-step buffer\n",
    "        self.n_step_buffer.append(transition)\n",
    "\n",
    "        # If the N-step buffer does not yet contain enough transitions for an N-step update\n",
    "        if len(self.n_step_buffer) < self.n_step:\n",
    "            return ()  # Return an empty tuple (no N-step transition available yet)\n",
    "        \n",
    "        # Compute the N-step reward, next observation, and done flag using the transitions\n",
    "        rew, next_obs, done = self._get_n_step_info(\n",
    "            self.n_step_buffer, self.gamma\n",
    "        )\n",
    "        # Retrieve the initial observation and action from the first transition in the buffer\n",
    "        obs, act = self.n_step_buffer[0][:2]\n",
    "        \n",
    "        # Store the computed transition components in the respective buffers\n",
    "        self.obs_buf[self.ptr] = obs  # Store the initial observation\n",
    "        self.next_obs_buf[self.ptr] = next_obs  # Store the N-step next observation\n",
    "        self.acts_buf[self.ptr] = act  # Store the action taken\n",
    "        self.rews_buf[self.ptr] = rew  # Store the N-step cumulative reward\n",
    "        self.done_buf[self.ptr] = done  # Store the terminal state flag\n",
    "        \n",
    "        # Update the pointer to the next position (circular buffer logic)\n",
    "        self.ptr = (self.ptr + 1) % self.max_size\n",
    "        # Update the size of the buffer (capped at max_size)\n",
    "        self.size = min(self.size + 1, self.max_size)\n",
    "        \n",
    "        # Return the first transition in the N-step buffer (primarily for debugging or chaining)\n",
    "        return self.n_step_buffer[0]\n",
    "\n",
    "\n",
    "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
    "        # Randomly select a batch of indices from the stored transitions\n",
    "        # `replace=False` ensures that no index is repeated in the sample\n",
    "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
    "\n",
    "        # Create and return a dictionary containing the sampled batch of transitions\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],          # Sampled observations (states)\n",
    "            next_obs=self.next_obs_buf[idxs],  # Sampled next observations (next states)\n",
    "            acts=self.acts_buf[idxs],        # Sampled actions\n",
    "            rews=self.rews_buf[idxs],        # Sampled rewards\n",
    "            done=self.done_buf[idxs],        # Sampled done flags (indicates terminal states)\n",
    "            indices=idxs,                    # Indices of the sampled transitions (useful for tracking or debugging)\n",
    "        )\n",
    "\n",
    "    \n",
    "    def sample_batch_from_idxs(\n",
    "        self, idxs: np.ndarray\n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "        # Retrieves a batch of transitions from the replay buffer using the provided indices\n",
    "        return dict(\n",
    "            obs=self.obs_buf[idxs],          # Observations (states) at the specified indices\n",
    "            next_obs=self.next_obs_buf[idxs],  # Next observations (next states) at the specified indices\n",
    "            acts=self.acts_buf[idxs],        # Actions taken at the specified indices\n",
    "            rews=self.rews_buf[idxs],        # Rewards received at the specified indices\n",
    "            done=self.done_buf[idxs],        # Done flags (indicating terminal states) at the specified indices\n",
    "        )\n",
    "    \n",
    "    def _get_n_step_info(\n",
    "        self, n_step_buffer: Deque, gamma: float\n",
    "    ) -> Tuple[np.int64, np.ndarray, bool]:\n",
    "        \"\"\"Return n step rew, next_obs, and done.\"\"\"\n",
    "        # Start with the reward, next observation, and done flag of the last transition\n",
    "        rew, next_obs, done = n_step_buffer[-1][-3:]\n",
    "        # Iterate through the transitions in reverse (excluding the last one) to compute:\n",
    "        # - The total discounted reward over the n-step trajectory\n",
    "        # - The next observation and done flag, adjusted to account for the earliest termination\n",
    "        for transition in reversed(list(n_step_buffer)[:-1]):\n",
    "            r, n_o, d = transition[-3:]\n",
    "            # Accumulate discounted reward while considering termination (done)\n",
    "            rew = r + gamma * rew * (1 - d)\n",
    "            # Update next_obs and done; prioritize the first occurrence of 'done=True'\n",
    "            next_obs, done = (n_o, d) if d else (next_obs, done)\n",
    "        return rew, next_obs, done\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # Returns the current size of the buffer (number of transitions stored)\n",
    "        # This is useful for checking how many transitions are currently available in the buffer\n",
    "        return self.size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prioritized replay Buffer\n",
    "\n",
    "`store` method returns boolean in order to inform if a N-step transition has been generated.\n",
    "\n",
    "(Please see *02.per.ipynb* for detailed description about PER.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer(ReplayBuffer):\n",
    "    \"\"\"Prioritized Replay buffer.\n",
    "    \n",
    "    Attributes:\n",
    "        max_priority (float): max priority\n",
    "        tree_ptr (int): next index of tree\n",
    "        alpha (float): alpha parameter for prioritized replay buffer\n",
    "        sum_tree (SumSegmentTree): sum tree for prior\n",
    "        min_tree (MinSegmentTree): min tree for min prior to get max weight\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        obs_dim: int,        # Dimension of the observations (e.g., for images or states)\n",
    "        size: int,           # Maximum size of the replay buffer\n",
    "        batch_size: int = 32, # Batch size to sample from the buffer\n",
    "        alpha: float = 0.6,   # Hyperparameter controlling prioritization of experiences\n",
    "        n_step: int = 1,      # Number of steps for n-step returns\n",
    "        gamma: float = 0.99,  # Discount factor for future rewards\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        # Ensure that alpha is non-negative, as it controls how much priority influences sampling\n",
    "        assert alpha >= 0\n",
    "        # Call the parent class constructor to initialize the common buffer attributes\n",
    "        super(PrioritizedReplayBuffer, self).__init__(\n",
    "            obs_dim, size, batch_size, n_step, gamma\n",
    "        )\n",
    "        # Initialize max_priority to 1.0 and tree_ptr (pointer to the current tree index) to 0\n",
    "        self.max_priority, self.tree_ptr = 1.0, 0\n",
    "        self.alpha = alpha  # Set alpha, which controls the prioritization\n",
    "        # Ensure that the tree capacity is a power of 2 (required for Segment Trees)\n",
    "        tree_capacity = 1\n",
    "        while tree_capacity < self.max_size:\n",
    "            tree_capacity *= 2\n",
    "        # Initialize SumSegmentTree to store the sum of priorities for proportional sampling\n",
    "        self.sum_tree = SumSegmentTree(tree_capacity)\n",
    "        # Initialize MinSegmentTree to store the minimum priority for computing importance sampling weights\n",
    "        self.min_tree = MinSegmentTree(tree_capacity)\n",
    "\n",
    "        \n",
    "    def store(\n",
    "        self, \n",
    "        obs: np.ndarray,         # Current observation (state)\n",
    "        act: int,                # Action taken\n",
    "        rew: float,              # Reward received\n",
    "        next_obs: np.ndarray,    # Next observation (state)\n",
    "        done: bool,              # Whether the episode has ended\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, float, np.ndarray, bool]:\n",
    "        \"\"\"Store experience and priority.\"\"\"\n",
    "        # Store the experience in the parent class's store method, which handles the buffer storage\n",
    "        transition = super().store(obs, act, rew, next_obs, done)\n",
    "        # If the experience was successfully stored (transition is not None)\n",
    "        if transition:\n",
    "            # Set the priority of the current experience in both SumSegmentTree and MinSegmentTree\n",
    "            # The priority is set as the maximum priority raised to the power of alpha\n",
    "            self.sum_tree[self.tree_ptr] = self.max_priority ** self.alpha\n",
    "            self.min_tree[self.tree_ptr] = self.max_priority ** self.alpha   \n",
    "            # Update the tree pointer (used to insert at the next index)\n",
    "            self.tree_ptr = (self.tree_ptr + 1) % self.max_size\n",
    "        # Return the stored experience (transition)\n",
    "        return transition\n",
    "\n",
    "\n",
    "    def sample_batch(self, beta: float = 0.4) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        # Assert that the current buffer size is at least as large as the batch size\n",
    "        assert len(self) >= self.batch_size\n",
    "        # Assert that beta is positive, as it controls the strength of the importance sampling correction\n",
    "        assert beta > 0 \n",
    "        # Sample a batch of indices based on priority-proportional sampling\n",
    "        indices = self._sample_proportional()\n",
    "        # Retrieve the corresponding experiences (observations, actions, rewards, next observations, and done flags)\n",
    "        obs = self.obs_buf[indices]         # Observations (states) for the sampled indices\n",
    "        next_obs = self.next_obs_buf[indices]  # Next observations (next states) for the sampled indices\n",
    "        acts = self.acts_buf[indices]       # Actions taken for the sampled experiences\n",
    "        rews = self.rews_buf[indices]      # Rewards received for the sampled experiences\n",
    "        done = self.done_buf[indices]      # Whether the episode was done (True/False)\n",
    "        # Calculate the importance-sampling weights for the sampled experiences\n",
    "        weights = np.array([self._calculate_weight(i, beta) for i in indices])\n",
    "        # Return a dictionary with all the relevant experience information and their importance-sampling weights\n",
    "        return dict(\n",
    "            obs=obs,\n",
    "            next_obs=next_obs,\n",
    "            acts=acts,\n",
    "            rews=rews,\n",
    "            done=done,\n",
    "            weights=weights,\n",
    "            indices=indices,\n",
    "        )\n",
    "\n",
    "        \n",
    "    def update_priorities(self, indices: List[int], priorities: np.ndarray):\n",
    "        \"\"\"Update priorities of sampled transitions.\"\"\"\n",
    "        # Ensure that the number of indices matches the number of priorities provided\n",
    "        assert len(indices) == len(priorities)\n",
    "        # Iterate over each index and its corresponding priority\n",
    "        for idx, priority in zip(indices, priorities):   \n",
    "            # Ensure that the priority is positive, as priorities cannot be negative or zero\n",
    "            assert priority > 0\n",
    "            # Ensure the index is within the bounds of the buffer\n",
    "            assert 0 <= idx < len(self)\n",
    "            # Update the priority in both SumSegmentTree and MinSegmentTree at the specified index\n",
    "            # The priority is raised to the power of alpha to control how much it influences sampling\n",
    "            self.sum_tree[idx] = priority ** self.alpha\n",
    "            self.min_tree[idx] = priority ** self.alpha\n",
    "            # Update the max priority if the new priority is higher than the current max priority\n",
    "            self.max_priority = max(self.max_priority, priority)\n",
    "\n",
    "            \n",
    "    def _sample_proportional(self) -> List[int]:\n",
    "        \"\"\"Sample indices based on proportions.\"\"\"\n",
    "        # Initialize an empty list to store the sampled indices\n",
    "        indices = []\n",
    "        # Calculate the total sum of priorities stored in the sum tree\n",
    "        # This represents the total \"weight\" of all experiences in the buffer\n",
    "        p_total = self.sum_tree.sum(0, len(self) - 1)\n",
    "        # Determine the size of each segment to divide the total priority sum into\n",
    "        # This will help us sample proportional to the priorities\n",
    "        segment = p_total / self.batch_size\n",
    "        # Loop over the batch size to sample 'batch_size' number of experiences\n",
    "        for i in range(self.batch_size):\n",
    "            # Define the range for the current segment (i-th segment)\n",
    "            a = segment * i  # Lower bound of the segment\n",
    "            b = segment * (i + 1)  # Upper bound of the segment\n",
    "            # Randomly pick a value between the lower and upper bounds of the segment\n",
    "            upperbound = random.uniform(a, b)\n",
    "            # Use the sum tree to retrieve the index of the experience whose cumulative priority \n",
    "            # is closest to the randomly chosen upperbound\n",
    "            idx = self.sum_tree.retrieve(upperbound)\n",
    "            # Append the retrieved index to the list of indices\n",
    "            indices.append(idx)\n",
    "        # Return the list of sampled indices\n",
    "        return indices\n",
    "\n",
    "    \n",
    "    def _calculate_weight(self, idx: int, beta: float):\n",
    "        \"\"\"Calculate the weight of the experience at idx.\"\"\"\n",
    "        # Get the minimum priority from the min_tree and normalize it by dividing by the total sum of priorities\n",
    "        p_min = self.min_tree.min() / self.sum_tree.sum()\n",
    "        # Calculate the maximum weight, which is used for normalizing the weight of each sample\n",
    "        # The max weight is based on the minimum priority in the buffer, the total number of experiences, and the beta parameter\n",
    "        max_weight = (p_min * len(self)) ** (-beta)\n",
    "        # Calculate the weight for the sample at index `idx`\n",
    "        # `p_sample` is the normalized priority of the experience at `idx` (i.e., priority of that sample divided by total priority sum)\n",
    "        p_sample = self.sum_tree[idx] / self.sum_tree.sum()\n",
    "        # The weight is computed by raising `p_sample` to the power of `(-beta)`, which adjusts the importance of the sample\n",
    "        weight = (p_sample * len(self)) ** (-beta)\n",
    "        # Normalize the weight by dividing it by the maximum weight\n",
    "        weight = weight / max_weight\n",
    "        # Return the calculated weight for the experience at index `idx`\n",
    "        return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Layer\n",
    "\n",
    "Please see *05.noisy_net.ipynb* for detailed description.\n",
    "\n",
    "**References:**\n",
    "\n",
    "- https://github.com/higgsfield/RL-Adventure/blob/master/5.noisy%20dqn.ipynb\n",
    "- https://github.com/Kaixhin/Rainbow/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    \"\"\"Noisy linear module for NoisyNet.\n",
    "    \n",
    "    \n",
    "        \n",
    "    Attributes:\n",
    "        in_features (int): input size of linear module\n",
    "        out_features (int): output size of linear module\n",
    "        std_init (float): initial std value\n",
    "        weight_mu (nn.Parameter): mean value weight parameter\n",
    "        weight_sigma (nn.Parameter): std value weight parameter\n",
    "        bias_mu (nn.Parameter): mean value bias parameter\n",
    "        bias_sigma (nn.Parameter): std value bias parameter\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int,  # Number of input features to the layer\n",
    "        out_features: int,  # Number of output features from the layer\n",
    "        std_init: float = 0.5,  # Initial standard deviation for the noise\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(NoisyLinear, self).__init__()  # Call to the parent class (nn.Module) constructor\n",
    "        # Store the input and output feature sizes, and the standard deviation for the noise\n",
    "        self.in_features = in_features  \n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "        # Create the parameters for the weight mean (mu) and standard deviation (sigma)\n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))  # Weight mean (mu) for the weights\n",
    "        self.weight_sigma = nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features)  # Weight standard deviation (sigma) for the weights\n",
    "        )\n",
    "        # Register a buffer to hold the noise (epsilon) for the weights (no need to optimize this buffer)\n",
    "        self.register_buffer(\n",
    "            \"weight_epsilon\", torch.Tensor(out_features, in_features)  # Noise for weights\n",
    "        )\n",
    "        # Create the parameters for the bias mean (mu) and standard deviation (sigma)\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features))  # Bias mean (mu) for the biases\n",
    "        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))  # Bias standard deviation (sigma) for the biases\n",
    "        # Register a buffer to hold the noise (epsilon) for the biases (no need to optimize this buffer)\n",
    "        self.register_buffer(\"bias_epsilon\", torch.Tensor(out_features))  # Noise for biases\n",
    "        # Initialize the parameters (weights and biases) with reasonable values\n",
    "        self.reset_parameters()\n",
    "        # Initialize the noise (random noise for weights and biases)\n",
    "        self.reset_noise()\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Reset trainable network parameters (factorized gaussian noise).\"\"\"\n",
    "        # Calculate the range for initializing the weight mean (mu) values\n",
    "        mu_range = 1 / math.sqrt(self.in_features)  # Standard deviation scaled by input size (Xavier initialization)\n",
    "        # Initialize weight mean (mu) values with a uniform distribution in the range [-mu_range, mu_range]\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        # Initialize the weight standard deviation (sigma) with a fixed value scaled by input size\n",
    "        self.weight_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.in_features)  # Standard deviation for weights (depends on input size)\n",
    "        )\n",
    "        # Initialize bias mean (mu) values with a uniform distribution in the range [-mu_range, mu_range]\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        # Initialize the bias standard deviation (sigma) with a fixed value scaled by output size\n",
    "        self.bias_sigma.data.fill_(\n",
    "            self.std_init / math.sqrt(self.out_features)  # Standard deviation for biases (depends on output size)\n",
    "        )\n",
    "\n",
    "\n",
    "    def reset_noise(self):\n",
    "        \"\"\"Make new noise.\"\"\"\n",
    "        # Generate noise for the input features using the scale_noise function\n",
    "        epsilon_in = self.scale_noise(self.in_features)  # Random noise for input size\n",
    "        # Generate noise for the output features using the scale_noise function\n",
    "        epsilon_out = self.scale_noise(self.out_features)  # Random noise for output size\n",
    "        # Outer product of the two noise vectors (input and output noise)\n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))  # Create the weight noise (outer product)\n",
    "        # Copy the output noise directly to the bias noise\n",
    "        self.bias_epsilon.copy_(epsilon_out)  # Use output noise for the bias noise\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\n",
    "        \n",
    "        We don't use separate statements on train / eval mode.\n",
    "        It doesn't show remarkable difference of performance.\n",
    "        \"\"\"\n",
    "        # Perform a linear transformation with perturbed weights and biases\n",
    "        return F.linear(\n",
    "            x,  # Input tensor 'x'\n",
    "            # Perturbed weights: weight_mu + (weight_sigma * weight_epsilon)\n",
    "            self.weight_mu + self.weight_sigma * self.weight_epsilon,  # Perturbed weights\n",
    "            # Perturbed biases: bias_mu + (bias_sigma * bias_epsilon)\n",
    "            self.bias_mu + self.bias_sigma * self.bias_epsilon,  # Perturbed biases\n",
    "        )\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_noise(size: int) -> torch.Tensor:\n",
    "        \"\"\"Set scale to make noise (factorized gaussian noise).\"\"\"\n",
    "        # Generate a tensor of random values from a normal distribution (Gaussian noise)\n",
    "        x = torch.randn(size)  # Create a tensor of random values with the specified size\n",
    "        # Scale the noise by taking the absolute value, then applying square root\n",
    "        # The 'sign()' function preserves the sign (positive or negative) of each element in 'x'\n",
    "        # The 'mul()' function performs element-wise multiplication with the transformed absolute values\n",
    "        return x.sign().mul(x.abs().sqrt())  # Return scaled noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoisyNet + DuelingNet + Categorical DQN\n",
    "\n",
    "#### NoisyNet + DuelingNet\n",
    "\n",
    "NoisyLinear is employed for the last two layers of advantage and value layers. The noise should be reset at evey update step.\n",
    "\n",
    "#### DuelingNet + Categorical DQN\n",
    "\n",
    "The dueling network architecture is adapted for use with return distributions. The network has a shared representation, which is then fed into a value stream with atom_size outputs, and into an advantage stream with atom_size × out_dim outputs. For each atom, the value and advantage streams are aggregated, as in dueling DQN, and then passed through a softmax layer to obtain the normalized parametric distributions used to estimate the returns’ distributions.\n",
    "\n",
    "```\n",
    "        advantage = self.advantage_layer(adv_hid).view(-1, self.out_dim, self.atom_size)\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        \n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "```\n",
    "\n",
    "(Please see *04.dueling.ipynb*, *05.noisy_net.ipynb*, *06.categorical_dqn.ipynb* for detailed description of each component's network architecture.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim: int, \n",
    "        out_dim: int, \n",
    "        atom_size: int, \n",
    "        support: torch.Tensor\n",
    "    ):\n",
    "        \"\"\"Initialization.\"\"\"\n",
    "        super(Network, self).__init__()\n",
    "        self.support = support  # The set of atoms (possible Q-values).\n",
    "        self.out_dim = out_dim  # Number of possible actions (output dimension).\n",
    "        self.atom_size = atom_size  # Number of discrete atoms for Q-value distribution.\n",
    "        # Feature layer: A fully connected layer followed by ReLU activation.\n",
    "        self.feature_layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128),  # Linear layer to map input to 128 features.\n",
    "            nn.ReLU(),  # ReLU activation to add non-linearity.\n",
    "        )\n",
    "        # Advantage layer: Two noisy layers, one for the hidden layer and one for the advantage output.\n",
    "        self.advantage_hidden_layer = NoisyLinear(128, 128)  # Hidden layer with noise.\n",
    "        self.advantage_layer = NoisyLinear(128, out_dim * atom_size)  # Advantage output layer with noise.\n",
    "        # Value layer: Two noisy layers, one for the hidden layer and one for the value output.\n",
    "        self.value_hidden_layer = NoisyLinear(128, 128)  # Hidden layer with noise.\n",
    "        self.value_layer = NoisyLinear(128, atom_size)  # Value output layer with noise.\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        dist = self.dist(x)  # Get the distribution over actions.\n",
    "        q = torch.sum(dist * self.support, dim=2)  # Compute the expected Q-value by summing over atoms.\n",
    "        return q\n",
    "\n",
    "    \n",
    "    def dist(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get distribution for atoms.\"\"\"\n",
    "        feature = self.feature_layer(x)  # Extract features from the input.\n",
    "        adv_hid = F.relu(self.advantage_hidden_layer(feature))  # Pass through the advantage hidden layer.\n",
    "        val_hid = F.relu(self.value_hidden_layer(feature))  # Pass through the value hidden layer.\n",
    "        # Advantage and value computation.\n",
    "        advantage = self.advantage_layer(adv_hid).view(\n",
    "            -1, self.out_dim, self.atom_size  # Reshape advantage to match output dimensions.\n",
    "        )\n",
    "        value = self.value_layer(val_hid).view(-1, 1, self.atom_size)  # Reshape value to match atoms.\n",
    "        # Compute Q-values (value + advantage - mean advantage).\n",
    "        q_atoms = value + advantage - advantage.mean(dim=1, keepdim=True)\n",
    "        # Apply softmax to normalize the Q-values into a probability distribution.\n",
    "        dist = F.softmax(q_atoms, dim=-1)\n",
    "        dist = dist.clamp(min=1e-3)  # To avoid NaNs, clamp the values to a minimum of 1e-3.\n",
    "        return dist\n",
    "\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        \"\"\"Reset all noisy layers.\"\"\"\n",
    "        self.advantage_hidden_layer.reset_noise()  # Reset noise for advantage hidden layer.\n",
    "        self.advantage_layer.reset_noise()  # Reset noise for advantage output layer.\n",
    "        self.value_hidden_layer.reset_noise()  # Reset noise for value hidden layer.\n",
    "        self.value_layer.reset_noise()  # Reset noise for value output layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainbow Agent\n",
    "\n",
    "Here is a summary of DQNAgent class.\n",
    "\n",
    "| Method           | Note                                                 |\n",
    "| ---              | ---                                                  |\n",
    "|select_action     | select an action from the input state.               |\n",
    "|step              | take an action and return the response of the env.   |\n",
    "|compute_dqn_loss  | return dqn loss.                                     |\n",
    "|update_model      | update the model by gradient descent.                |\n",
    "|target_hard_update| hard update from the local model to the target model.|\n",
    "|train             | train the agent during num_frames.                   |\n",
    "|test              | test the agent (1 episode).                          |\n",
    "|plot              | plot the training progresses.                        |\n",
    "\n",
    "#### Categorical DQN + Double DQN\n",
    "\n",
    "The idea of Double Q-learning is to reduce overestimations by decomposing the max operation in the target into action selection and action evaluation. Here, we use `self.dqn` instead of `self.dqn_target` to obtain the target actions.\n",
    "\n",
    "```\n",
    "        # Categorical DQN + Double DQN\n",
    "        # target_dqn is used when we don't employ double DQN\n",
    "        next_action = self.dqn(next_state).argmax(1)\n",
    "        next_dist = self.dqn_target.dist(next_state)\n",
    "        next_dist = next_dist[range(self.batch_size), next_action]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent interacting with environment.\n",
    "    \n",
    "    Attribute:\n",
    "        env (gym.Env): openAI Gym environment\n",
    "        memory (PrioritizedReplayBuffer): replay memory to store transitions\n",
    "        batch_size (int): batch size for sampling\n",
    "        target_update (int): period for target model's hard update\n",
    "        gamma (float): discount factor\n",
    "        dqn (Network): model to train and select actions\n",
    "        dqn_target (Network): target model to update\n",
    "        optimizer (torch.optim): optimizer for training dqn\n",
    "        transition (list): transition information including \n",
    "                           state, action, reward, next_state, done\n",
    "        v_min (float): min value of support\n",
    "        v_max (float): max value of support\n",
    "        atom_size (int): the unit number of support\n",
    "        support (torch.Tensor): support for categorical dqn\n",
    "        use_n_step (bool): whether to use n_step memory\n",
    "        n_step (int): step number to calculate n-step td error\n",
    "        memory_n (ReplayBuffer): n-step replay buffer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        env: gym.Env,\n",
    "        memory_size: int,\n",
    "        batch_size: int,\n",
    "        target_update: int,\n",
    "        seed: int,\n",
    "        gamma: float = 0.99,\n",
    "        # PER parameters\n",
    "        alpha: float = 0.2,\n",
    "        beta: float = 0.6,\n",
    "        prior_eps: float = 1e-6,\n",
    "        # Categorical DQN parameters\n",
    "        v_min: float = 0.0,\n",
    "        v_max: float = 200.0,\n",
    "        atom_size: int = 51,\n",
    "        # N-step Learning\n",
    "        n_step: int = 3,\n",
    "    ):\n",
    "        \"\"\"Initialization.\n",
    "        \n",
    "        Args:\n",
    "            env (gym.Env): openAI Gym environment\n",
    "            memory_size (int): length of memory\n",
    "            batch_size (int): batch size for sampling\n",
    "            target_update (int): period for target model's hard update\n",
    "            lr (float): learning rate\n",
    "            gamma (float): discount factor\n",
    "            alpha (float): determines how much prioritization is used\n",
    "            beta (float): determines how much importance sampling is used\n",
    "            prior_eps (float): guarantees every transition can be sampled\n",
    "            v_min (float): min value of support\n",
    "            v_max (float): max value of support\n",
    "            atom_size (int): the unit number of support\n",
    "            n_step (int): step number to calculate n-step td error\n",
    "        \"\"\"\n",
    "        # Get the dimensions of the observation and action spaces from the environment\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        action_dim = env.action_space.n\n",
    "        # Save the parameters\n",
    "        self.env = env\n",
    "        self.batch_size = batch_size  # Size of each batch when sampling from memory\n",
    "        self.target_update = target_update  # Frequency of updating target network\n",
    "        self.seed = seed  # Random seed for reproducibility\n",
    "        self.gamma = gamma  # Discount factor for future rewards\n",
    "        # Device setup: Use GPU if available, otherwise default to CPU\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(self.device)  # Print the device being used\n",
    "        # Prioritized Experience Replay (PER) settings\n",
    "        self.beta = beta  # Beta controls the importance sampling weight\n",
    "        self.prior_eps = prior_eps  # Small value added to priorities to ensure no zero priorities\n",
    "        self.memory = PrioritizedReplayBuffer(\n",
    "            obs_dim, memory_size, batch_size, alpha=alpha, gamma=gamma\n",
    "        )  # Initialize memory buffer for experience replay with prioritization\n",
    "        # N-step Learning memory\n",
    "        self.use_n_step = True if n_step > 1 else False  # Flag to determine if N-step learning is used\n",
    "        if self.use_n_step:\n",
    "            self.n_step = n_step  # Number of steps for N-step TD learning\n",
    "            self.memory_n = ReplayBuffer(\n",
    "                obs_dim, memory_size, batch_size, n_step=n_step, gamma=gamma\n",
    "            )  # Initialize memory for N-step transitions \n",
    "        # Categorical DQN parameters\n",
    "        self.v_min = v_min  # Minimum value of the categorical distribution support\n",
    "        self.v_max = v_max  # Maximum value of the categorical distribution support\n",
    "        self.atom_size = atom_size  # Number of atoms in the categorical distribution\n",
    "        self.support = torch.linspace(\n",
    "            self.v_min, self.v_max, self.atom_size\n",
    "        ).to(self.device)  # Create a support array (uniformly spaced values between v_min and v_max)\n",
    "        # Networks: initialize the DQN and target networks\n",
    "        self.dqn = Network(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)  # Main Q-network\n",
    "        self.dqn_target = Network(\n",
    "            obs_dim, action_dim, self.atom_size, self.support\n",
    "        ).to(self.device)  # Target Q-network\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())  # Initialize target network with main network weights\n",
    "        self.dqn_target.eval()  # Set the target network in evaluation mode\n",
    "        # Optimizer for the DQN\n",
    "        self.optimizer = optim.Adam(self.dqn.parameters())  # Adam optimizer for training the DQN\n",
    "        # Initialize transition list to store state transitions\n",
    "        self.transition = list()\n",
    "        # Mode flag (True for testing, False for training)\n",
    "        self.is_test = False\n",
    "\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Select an action from the input state.\"\"\"\n",
    "        # Pass the input state to the DQN model to get action probabilities\n",
    "        selected_action = self.dqn(\n",
    "            torch.FloatTensor(state).to(self.device)\n",
    "        ).argmax()  # Choose the action with the highest probability\n",
    "        # Convert the selected action to a numpy array for compatibility\n",
    "        selected_action = selected_action.detach().cpu().numpy()\n",
    "        # If the agent is not in test mode, store the current state and action as transition data\n",
    "        if not self.is_test:\n",
    "            self.transition = [state, selected_action]\n",
    "        # Return the selected action\n",
    "        return selected_action\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
    "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
    "        # Take the action in the environment and get the next state, reward, \n",
    "        # whether the episode is terminated, and whether it was truncated\n",
    "        next_state, reward, terminated, truncated, _ = self.env.step(action)\n",
    "        done = terminated or truncated  # Determine if the episode is done\n",
    "        # If the agent is not in test mode, store the transition details\n",
    "        if not self.is_test:\n",
    "            self.transition += [reward, next_state, done]\n",
    "            # If using N-step learning, store the transition in the N-step memory\n",
    "            if self.use_n_step:\n",
    "                one_step_transition = self.memory_n.store(*self.transition)\n",
    "            # If using 1-step learning, store the transition in regular memory\n",
    "            else:\n",
    "                one_step_transition = self.transition\n",
    "            # Add the transition to memory\n",
    "            if one_step_transition:\n",
    "                self.memory.store(*one_step_transition)\n",
    "        # Return the next state, reward, and whether the episode is done\n",
    "        return next_state, reward, done\n",
    "\n",
    "\n",
    "    def update_model(self) -> torch.Tensor:\n",
    "        \"\"\"Update the model by gradient descent.\"\"\"\n",
    "        # Sample a batch from the experience replay memory using the current beta value.\n",
    "        # This is important for Prioritized Experience Replay (PER), which calculates weights based on the importance of the experiences.\n",
    "        samples = self.memory.sample_batch(self.beta)\n",
    "        # Retrieve the importance sampling weights and ensure they have the correct shape.\n",
    "        weights = torch.FloatTensor(\n",
    "            samples[\"weights\"].reshape(-1, 1)\n",
    "        ).to(self.device)  # Move weights to the correct device (CPU or GPU)\n",
    "        # Indices of the sampled batch, which will be used later to update priorities.\n",
    "        indices = samples[\"indices\"]\n",
    "        # Compute the 1-step learning loss using the DQN loss function.\n",
    "        # This is the regular loss used when the agent takes actions one step at a time.\n",
    "        elementwise_loss = self._compute_dqn_loss(samples, self.gamma)\n",
    "        # Apply importance sampling by multiplying the loss with the weights.\n",
    "        # This helps in correcting the bias introduced by prioritized experience replay.\n",
    "        loss = torch.mean(elementwise_loss * weights)\n",
    "        # If N-step learning is enabled, we compute the N-step learning loss.\n",
    "        # We combine the 1-step loss and N-step loss to avoid high variance.\n",
    "        # The original Rainbow DQN algorithm uses only the N-step loss, but combining both can stabilize training.\n",
    "        if self.use_n_step:\n",
    "            gamma = self.gamma ** self.n_step  # Discount factor for N-step learning\n",
    "            samples = self.memory_n.sample_batch_from_idxs(indices)  # Sample N-step batch\n",
    "            elementwise_loss_n_loss = self._compute_dqn_loss(samples, gamma)  # Compute N-step loss\n",
    "            elementwise_loss += elementwise_loss_n_loss  # Combine 1-step and N-step loss\n",
    "            # Again apply importance sampling with the updated combined loss.\n",
    "            loss = torch.mean(elementwise_loss * weights)\n",
    "        # Perform gradient descent optimization step.\n",
    "        self.optimizer.zero_grad()  # Reset gradients to zero before the backward pass.\n",
    "        loss.backward()  # Compute gradients for backpropagation.\n",
    "        # Clip the gradients to prevent large updates that might cause instability in training.\n",
    "        clip_grad_norm_(self.dqn.parameters(), 10.0)\n",
    "        # Perform the optimization step, updating the DQN network's parameters.\n",
    "        self.optimizer.step()\n",
    "        # Update the priorities of the sampled experiences in memory.\n",
    "        # This is done after the loss calculation to ensure that more important experiences are given higher priority in future sampling.\n",
    "        loss_for_prior = elementwise_loss.detach().cpu().numpy()  # Detach the loss from the computation graph for priority update\n",
    "        new_priorities = loss_for_prior + self.prior_eps  # Add a small constant to avoid zero priorities\n",
    "        self.memory.update_priorities(indices, new_priorities)  # Update the priorities in the memory buffer\n",
    "        # Reset the noise in the NoisyNet layers, as part of the NoisyNet DQN algorithm.\n",
    "        self.dqn.reset_noise()  # Reset noise in the online DQN network.\n",
    "        self.dqn_target.reset_noise()  # Reset noise in the target DQN network.\n",
    "        # Return the computed loss value as a scalar.\n",
    "        return loss.item()  # Return loss as a Python float (scaler) to avoid PyTorch tensor overhead.\n",
    "\n",
    "        \n",
    "    def train(self, num_frames: int, plotting_interval: int = 200):\n",
    "        \"\"\"Train the agent.\"\"\"\n",
    "        self.is_test = False  # Set the agent to training mode, enabling exploration policies\n",
    "        # Initialize the environment and get the initial state\n",
    "        state, _ = self.env.reset(seed=self.seed)\n",
    "        update_cnt = 0  # Initialize the update count\n",
    "        losses = []  # Initialize the list to store losses during training\n",
    "        scores = []  # Initialize the list to store scores during training\n",
    "        score = 0  # Initialize the score (total reward) to 0\n",
    "        # Loop through each frame for training\n",
    "        for frame_idx in range(1, num_frames + 1):\n",
    "            # Select an action based on the current state\n",
    "            action = self.select_action(state)\n",
    "            # Take the selected action and get the next state, reward, and done flag\n",
    "            next_state, reward, done = self.step(action)\n",
    "            # Update the state and accumulate the reward\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            # NoisyNet: Removed epsilon decay logic\n",
    "            # PER: Increase the importance sampling weight (beta)\n",
    "            fraction = min(frame_idx / num_frames, 1.0)  # Calculate fraction for increasing beta\n",
    "            self.beta = self.beta + fraction * (1.0 - self.beta)  # Increase beta gradually\n",
    "            # If episode ends, reset the environment and record the score\n",
    "            if done:\n",
    "                state, _ = self.env.reset(seed=self.seed)  # Reset the environment\n",
    "                scores.append(score)  # Append the total score of the episode\n",
    "                score = 0  # Reset the score for the next episode\n",
    "            # If training is ready (sufficient experience in memory)\n",
    "            if len(self.memory) >= self.batch_size:\n",
    "                # Update the model based on samples from the memory\n",
    "                loss = self.update_model()\n",
    "                losses.append(loss)  # Record the loss\n",
    "                update_cnt += 1  # Increment the update count\n",
    "                # Perform a hard update of the target network after certain number of updates\n",
    "                if update_cnt % self.target_update == 0:\n",
    "                    self._target_hard_update()\n",
    "            # Plot the training progress periodically\n",
    "            if frame_idx % plotting_interval == 0:\n",
    "                self._plot(frame_idx, scores, losses)           \n",
    "        self.env.close()  # Close the environment after training\n",
    "\n",
    "                \n",
    "    def test(self, video_folder: str) -> None:\n",
    "        \"\"\"Test the agent.\"\"\"\n",
    "        # Set the agent to test mode, disabling any exploration policies\n",
    "        self.is_test = True\n",
    "        # Create a recording environment to capture a video of the agent's behavior\n",
    "        naive_env = self.env  # Save the original environment\n",
    "        self.env = gym.wrappers.RecordVideo(self.env, video_folder=video_folder)  # Wrap the environment to record a video\n",
    "        # Reset the environment and get the initial state\n",
    "        state, _ = self.env.reset(seed=self.seed)  # Reset the environment and get the initial state\n",
    "        done = False  # Initialize the done flag as False (episode not over)\n",
    "        score = 0  # Initialize the score (total reward) to 0\n",
    "        # Run the episode until done (when the agent reaches a terminal state)\n",
    "        while not done:\n",
    "            # Select the action based on the current state\n",
    "            action = self.select_action(state)\n",
    "            # Take the selected action and get the next state, reward, and done flag\n",
    "            next_state, reward, done = self.step(action)\n",
    "            # Update the state and accumulate the reward\n",
    "            state = next_state\n",
    "            score += reward  # Add the reward to the total score\n",
    "        # Print the total score achieved in the episode\n",
    "        print(\"score: \", score) \n",
    "        # Close the environment (stop video recording)\n",
    "        self.env.close()\n",
    "        # Restore the original environment (remove the video recording wrapper)\n",
    "        self.env = naive_env\n",
    "\n",
    "\n",
    "    def _compute_dqn_loss(self, samples: Dict[str, np.ndarray], gamma: float) -> torch.Tensor:\n",
    "        \"\"\"Return categorical dqn loss.\"\"\"\n",
    "        device = self.device  # Device to store tensors (either CPU or GPU)\n",
    "        # Convert input samples (state, next state, action, reward, done) into tensors\n",
    "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
    "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
    "        action = torch.LongTensor(samples[\"acts\"]).to(device)\n",
    "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
    "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
    "        # Categorical DQN specific parameters\n",
    "        delta_z = float(self.v_max - self.v_min) / (self.atom_size - 1)  # Interval size for support\n",
    "        with torch.no_grad():\n",
    "            # Double DQN: Select actions using the main network and compute target distributions from the target network\n",
    "            next_action = self.dqn(next_state).argmax(1)  # Get the best action from the main network\n",
    "            next_dist = self.dqn_target.dist(next_state)  # Get the distribution from the target network\n",
    "            next_dist = next_dist[range(self.batch_size), next_action]  # Select the distribution corresponding to the chosen actions\n",
    "            # Compute the target distribution (t_z)\n",
    "            t_z = reward + (1 - done) * gamma * self.support  # Bellman update for categorical DQN\n",
    "            t_z = t_z.clamp(min=self.v_min, max=self.v_max)  # Clamp target to within [v_min, v_max]\n",
    "            b = (t_z - self.v_min) / delta_z  # Normalize target to the support\n",
    "            l = b.floor().long()  # Lower bound of the target bin\n",
    "            u = b.ceil().long()  # Upper bound of the target bin\n",
    "            # Create an offset for indexing the target distribution\n",
    "            offset = (\n",
    "                torch.linspace(\n",
    "                    0, (self.batch_size - 1) * self.atom_size, self.batch_size\n",
    "                ).long()\n",
    "                .unsqueeze(1)\n",
    "                .expand(self.batch_size, self.atom_size)\n",
    "                .to(self.device)\n",
    "            )\n",
    "            # Project the target distribution onto the bins\n",
    "            proj_dist = torch.zeros(next_dist.size(), device=self.device)  # Initialize projected distribution\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (l + offset).view(-1), (next_dist * (u.float() - b)).view(-1)\n",
    "            )  # Add the portion for the lower bin\n",
    "            proj_dist.view(-1).index_add_(\n",
    "                0, (u + offset).view(-1), (next_dist * (b - l.float())).view(-1)\n",
    "            )  # Add the portion for the upper bin\n",
    "        # Compute the categorical DQN loss using the projection and log of the predicted probabilities\n",
    "        dist = self.dqn.dist(state)  # Get the distribution of the current state from the DQN\n",
    "        log_p = torch.log(dist[range(self.batch_size), action])  # Log probabilities of chosen actions\n",
    "        elementwise_loss = -(proj_dist * log_p).sum(1)  # Compute the loss for each sample\n",
    "        return elementwise_loss  # Return the computed loss\n",
    "\n",
    "\n",
    "    def _target_hard_update(self):\n",
    "        \"\"\"Hard update: target <- local.\"\"\"\n",
    "        self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "                \n",
    "    def _plot(\n",
    "        self, \n",
    "        frame_idx: int,  # The current frame index (or timestep) during training\n",
    "        scores: List[float],  # List of scores obtained by the agent during training episodes\n",
    "        losses: List[float],  # List of loss values (training loss)\n",
    "    ):\n",
    "        \"\"\"Plot the training progress by displaying the score and loss over time.\"\"\"\n",
    "        clear_output(True)  # Clears previous outputs to update the plot in the notebook\n",
    "        plt.figure(figsize=(20, 5))  # Set the figure size for the plot\n",
    "        # Plot the scores (agent's performance over time)\n",
    "        plt.subplot(131)  # Create the first subplot (score plot)\n",
    "        plt.title('frame %s. score: %s' % (frame_idx, np.mean(scores[-10:])))  # Title includes the current frame index and average score over the last 10 episodes\n",
    "        plt.plot(scores)  # Plot the scores over time\n",
    "        # Plot the loss values (agent's training loss over time)\n",
    "        plt.subplot(132)  # Create the second subplot (loss plot)\n",
    "        plt.title('loss')  # Title of the plot\n",
    "        plt.plot(losses)  # Plot the losses over time\n",
    "        plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "You can see the [code](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py) and [configurations](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py#L91) of CartPole-v1 from Farama Gymnasium's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 777  # Set a specific seed value for reproducibility across runs.\n",
    "def seed_torch(seed):\n",
    "    \"\"\"Set the seed for PyTorch to ensure reproducibility.\"\"\"\n",
    "    torch.manual_seed(seed)  # Set the seed for PyTorch's random number generator (CPU)\n",
    "    # If using CUDA (GPU), set the seed for CUDA operations to ensure reproducibility on the GPU.\n",
    "    if torch.backends.cudnn.enabled:\n",
    "        torch.cuda.manual_seed(seed)  # Set the seed for GPU's random number generator.\n",
    "        torch.backends.cudnn.benchmark = False  # Disable benchmarking, making the convolution operations deterministic.\n",
    "        torch.backends.cudnn.deterministic = True  # Ensures deterministic behavior by using only deterministic algorithms in cuDNN.\n",
    "# Set the seed for other libraries (NumPy and Python's built-in random module) to ensure the whole environment is deterministic.\n",
    "np.random.seed(seed)  # Set the seed for NumPy's random number generator.\n",
    "random.seed(seed)  # Set the seed for Python's built-in random module.\n",
    "# Apply the seed settings to PyTorch to make its operations deterministic.\n",
    "seed_torch(seed)  # This function call applies the seed settings specifically for PyTorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "num_frames = 12000\n",
    "memory_size = 10000\n",
    "batch_size = 128\n",
    "target_update = 100\n",
    "# train\n",
    "agent = DQNAgent(env, memory_size, batch_size, target_update, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.train(num_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Run the trained agent (1 episode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/pytorch_env/lib/python3.8/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /Users/vishalsankarram/Desktop/github/rainbow-is-all-you-need-1/videos/rainbow folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/pytorch_env/lib/python3.8/site-packages/gymnasium/core.py:297: UserWarning: \u001b[33mWARN: env.is_vector_env to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_vector_env` for environment variables or `env.get_attr('is_vector_env')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /Users/vishalsankarram/Desktop/github/rainbow-is-all-you-need-1/videos/rainbow/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /Users/vishalsankarram/Desktop/github/rainbow-is-all-you-need-1/videos/rainbow/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/vishalsankarram/Desktop/github/rainbow-is-all-you-need-1/videos/rainbow/rl-video-episode-0.mp4\n",
      "score:  500.0\n"
     ]
    }
   ],
   "source": [
    "video_folder=\"videos/rainbow\"\n",
    "agent.test(video_folder=video_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <video width=\"320\" height=\"240\" alt=\"test\" controls>\n",
       "        <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"/>\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Played: videos/rainbow/rl-video-episode-0.mp4\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import glob\n",
    "import io\n",
    "import os\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def ipython_show_video(path: str) -> None:\n",
    "    \"\"\"Show a video at `path` within IPython Notebook.\"\"\"\n",
    "    if not os.path.isfile(path):\n",
    "        raise NameError(\"Cannot access: {}\".format(path))\n",
    "\n",
    "    video = io.open(path, \"r+b\").read()\n",
    "    encoded = base64.b64encode(video)\n",
    "\n",
    "    display(HTML(\n",
    "        data=\"\"\"\n",
    "        <video width=\"320\" height=\"240\" alt=\"test\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\"/>\n",
    "        </video>\n",
    "        \"\"\".format(encoded.decode(\"ascii\"))\n",
    "    ))\n",
    "\n",
    "\n",
    "def show_latest_video(video_folder: str) -> str:\n",
    "    \"\"\"Show the most recently recorded video from video folder.\"\"\"\n",
    "    list_of_files = glob.glob(os.path.join(video_folder, \"*.mp4\"))\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    ipython_show_video(latest_file)\n",
    "    return latest_file\n",
    "\n",
    "\n",
    "latest_file = show_latest_video(video_folder=video_folder)\n",
    "print(\"Played:\", latest_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
